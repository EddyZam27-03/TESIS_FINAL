# Ajustes para Modelo Full Body con Videos

## ‚úÖ Cambios Realizados

1. **`PoseDetector.kt`** - Creado para detectar full body (33 landmarks)
2. **`GestureClassifier.kt`** - Actualizado con soporte para m√∫ltiples frames
3. **`GestureRecognitionManager.kt`** - Cambiado a usar `PoseDetector` y soporte para videos

## ‚ö†Ô∏è Valores a Ajustar

### 1. Input Size en `GestureClassifier.kt`

**L√≠nea 15:** Cambia `inputSize` seg√∫n tu modelo:

```kotlin
// Ejecuta verificar_modelo.py para obtener el valor exacto
private val inputSize = 132 // ‚ö†Ô∏è CAMBIAR AQU√ç
```

**Valores comunes:**
- **132** = 1 frame de full body (33 landmarks √ó 4 valores)
- **1320** = 10 frames de full body (132 √ó 10)
- **2640** = 20 frames de full body (132 √ó 20)
- **3960** = 30 frames de full body (132 √ó 30)

### 2. N√∫mero de Frames en `GestureRecognitionManager.kt`

**L√≠nea 28:** Cambia `maxFrames` seg√∫n tu modelo:

```kotlin
private val maxFrames = 1 // ‚ö†Ô∏è CAMBIAR AQU√ç
```

**C√°lculo:**
```
maxFrames = inputSize / 132

Ejemplos:
- Si inputSize = 132 ‚Üí maxFrames = 1
- Si inputSize = 1320 ‚Üí maxFrames = 10
- Si inputSize = 2640 ‚Üí maxFrames = 20
```

## üîç C√≥mo Verificar Tu Modelo

### Opci√≥n 1: Usar el Script Python

```bash
python verificar_modelo.py
```

El script te dir√°:
- Input shape y size
- Si es full body o solo manos
- Si usa m√∫ltiples frames
- N√∫mero exacto de frames

### Opci√≥n 2: Verificar Manualmente

```python
import tensorflow as tf

interpreter = tf.lite.Interpreter(model_path="app/src/main/assets/INFO/modelo_lsp.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
input_shape = input_details[0]['shape']
input_size = input_shape[1]  # Ejemplo: [1, 1320]

print(f"Input size: {input_size}")
print(f"N√∫mero de frames: {input_size // 132}")
```

## üìã Checklist de Ajustes

1. [ ] Ejecutar `verificar_modelo.py` o verificar manualmente
2. [ ] Anotar el `input_size` del modelo
3. [ ] Calcular `maxFrames = input_size / 132`
4. [ ] Cambiar `inputSize` en `GestureClassifier.kt` l√≠nea 15
5. [ ] Cambiar `maxFrames` en `GestureRecognitionManager.kt` l√≠nea 28
6. [ ] Descargar `pose_landmark.tflite` de MediaPipe
7. [ ] Colocar en `app/src/main/assets/INFO/pose_landmark.tflite`
8. [ ] Compilar y probar

## üì• Modelo Necesario

**Archivo:** `pose_landmark.tflite`

**Descarga:**
- GitHub: https://github.com/google/mediapipe/tree/master/mediapipe/modules/pose_landmark
- Archivo: `pose_landmark_full.tflite` ‚Üí renombra a `pose_landmark.tflite`

**Ubicaci√≥n:** `app/src/main/assets/INFO/pose_landmark.tflite`

## üéØ Ejemplo de Ajuste

Si tu modelo tiene:
- **Input size: 1320**
- **Significa: 10 frames de full body**

**Ajustes:**
1. `GestureClassifier.kt` l√≠nea 15: `inputSize = 1320`
2. `GestureRecognitionManager.kt` l√≠nea 28: `maxFrames = 10`

## ‚ö†Ô∏è Notas Importantes

- Si `inputSize = 132`: El modelo usa **1 frame** (no videos)
- Si `inputSize > 132` y es m√∫ltiplo de 132: El modelo usa **videos**
- El c√≥digo autom√°ticamente detecta si usar 1 frame o m√∫ltiples frames
- Los landmarks son de **full body** (33 puntos), no solo manos

## üêõ Soluci√≥n de Problemas

**Error: "Input size mismatch"**
- Verifica que `inputSize` en `GestureClassifier.kt` coincida con tu modelo

**Error: "Model not found"**
- Descarga `pose_landmark.tflite` y col√≥calo en `app/src/main/assets/INFO/`

**No detecta gestos:**
- Verifica que `maxFrames` sea correcto
- Verifica que el modelo de pose est√© cargado correctamente






